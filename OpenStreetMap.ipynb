{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Data Wrangling Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenStreetMap Sample Project - Data Wrangling with MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Data Preparation\n",
    "\n",
    "**Map Area: Saint-Joseph - Île de La Réunion**\n",
    "- http://www.openstreetmap.org/relation/1282272#map=12/-21.2918/55.6440\n",
    "- http://overpass-api.de/api/map?bbox=55.4871,-21.4039,55.8009,-21.1796"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(filename='LaReunion.png', width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from openstreetmap import audit, shape\n",
    "from openstreetmap.data_gouv_fr import postalcode, fantoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OSM_FILE = \"data/Saint-Joseph.La-Reunion.osm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 - Auditing Data\n",
    "#### 1.1.1 - node and way xml tags\n",
    "\n",
    "A quick look at the different 'tag' available in our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!openstreetmap/tags.py -o data/Saint-Joseph.La-Reunion.osm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few tags are to be ignored for the rest of cleansing process as tag names contains problematic characters.\n",
    "\n",
    "The auditing will focus on the following tags (to illustrate the different checks that could be put in place for cleansing) from the remaining tags:\n",
    "- population, capacity, elevation, direction, phone, postal_code\n",
    "- addr:city, addr:postcode, addr:housenumber, addr:street\n",
    "\n",
    "other tags will be included \"as-is\".\n",
    "\n",
    "> **note:** City, Post Code, Street name and type will be checked against official data sources (see references in audit.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Official databases are filtered to limit the data for the area of interest aka 974**\n",
    "# All tag values not compliants with the rules defined are listed in associated files under audit folder\n",
    "# The diffirents files will be manually checked and updated for the next step in cleansing process\n",
    "!openstreetmap/audit.py -i -o data/Saint-Joseph.La-Reunion.osm -f data/FANTOIR1016 -a 974 -u audit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the auditing, the following problems have been identified:\n",
    "1. Some street types are wrongly spelled or abbreviated\n",
    "2. No street type information for some street (all street listed under one single entry 'None' in our audit results)\n",
    "3. Street name case not consistent (Full upercase, lowercase or mix)\n",
    "4. House number contain more than one number (grouping of several houses is not considered as an issue for the auditing process and the validation rule has been updated to take it into account)\n",
    "5. Same issue for the phone (e.g.: \"0692407639;0692407637\")\n",
    "6. Some city are wrongly spelled or case not consistent (Full upercase, lowercase or mix)\n",
    "7. An extra space inside postcode value + an unknown postcode value: 97447 to be replaced by 97442 according to the city name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - From XML to JSON to MongoDB\n",
    "\n",
    "#### 2.1 - Create JSON file\n",
    "\n",
    "Based on the cleansing identified in previous section, Some values are partially or fully updated during the JSON file generation from the data recovered from associated files under update folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!openstreetmap/shape.py -o data/Saint-Joseph.La-Reunion.osm -u update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 - MongoDB Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop previous database if any\n",
    "!mongo OpenStreetMap --eval \"db.dropDatabase()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mongoimport -d OpenStreetMap -c LaReunion --file data/Saint-Joseph.La-Reunion.osm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 - Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from bson.son import SON\n",
    "\n",
    "client = MongoClient()\n",
    "\n",
    "def pretty(documents):\n",
    "    for document in documents:\n",
    "        pprint.pprint(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = client.OpenStreetMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just peek the previously selected sample example from our python cleansing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pretty(db.LaReunion.find({\"id\": \"3480487005\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we have the same count as the result of our python cleansing code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.LaReunion.count() == 801017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of \"xml node\" imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\"$unwind\": \"$type\"},\n",
    "    {\"$group\": {\"_id\": \"$type\", \"count\": {\"$sum\": 1}}},\n",
    "    {\"$sort\": SON([(\"count\", -1), (\"_id\", -1)])}\n",
    "]\n",
    "nodes = pd.DataFrame(list(db.LaReunion.aggregate(pipeline)))\n",
    "nodes.columns = [\"node\", \"count\"]\n",
    "nodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different users have contributed to this database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(db.LaReunion.find().distinct(\"created.user\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When did the contribution take place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\"$project\": {\"_id\": False, \"timestamp\":  \"$created.timestamp\", \"user\": \"$created.user\" } },\n",
    "    {\"$group\": {\"_id\": \"$timestamp\",  \"users\": { \"$sum\": 1 }}}\n",
    "]\n",
    "contributions = pd.DataFrame(list(db.LaReunion.aggregate(pipeline)))\n",
    "contributions[\"_id\"] = pd.to_datetime(contributions._id)\n",
    "contributions.columns = [\"date\", \"users\"]\n",
    "axes = contributions.set_index(['date']).plot(figsize=(12,6), title=\"Number of users contribution by date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have quite recent contributions for this dataset, let's identify the top 10 contributors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    { \"$project\": { \"_id\": False, \"user\": \"$created.user\" } },\n",
    "    { \"$group\": { \"_id\": \"$user\", \"count\": { \"$sum\": 1 } } },\n",
    "    { \"$sort\": SON([(\"count\", -1), (\"_id\", -1)]) },\n",
    "    { \"$limit\": 10 }\n",
    "]\n",
    "pretty(list(db.LaReunion.aggregate(pipeline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can consider having 1 top contributor followed by 5 high contributors... let see the distribution of the contribution for all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    { \"$project\": { \"_id\": False, \"user\": \"$created.user\" } },\n",
    "    { \"$group\": { \"_id\": \"$user\", \"count\": { \"$sum\": 1 } } },\n",
    "    { \"$sort\": SON([(\"count\", -1), (\"_id\", -1)]) },\n",
    "    { \"$project\": { \"_id\": \"$count\"} }\n",
    "]\n",
    "contributions = pd.DataFrame(list(db.LaReunion.aggregate(pipeline)))\n",
    "contributions.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above ouput clearly show that we have outliers in term of user contribution... just see if mongodb can provide us the distribution of the all users contribution with a predefined bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    { \"$project\": { \"_id\": False, \"user\": \"$created.user\" } },\n",
    "    { \"$group\": { \"_id\": \"$user\", \"count\": { \"$sum\": 1 } } },\n",
    "    {\n",
    "        \"$bucket\": {\n",
    "            \"groupBy\": \"$count\",\n",
    "            \"boundaries\": [ 1, 100, 10000, 25000, 100000 ],\n",
    "            \"default\": \"TOP\",\n",
    "            \"output\": {\n",
    "              \"count\": { \"$sum\": 1 },\n",
    "              \"users\": { \"$push\": \"$_id\" }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "contributions = pd.DataFrame(list(db.LaReunion.aggregate(pipeline)))\n",
    "contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result confirm that most user are below 100 contributions and the main contributors are composed of 5 high contributors  and TOP contributor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - How MongoDb will ease the data cleansing process...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First focus on all document with type='node' and having a subdocument 'address'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    { \"$match\": { \"type\": \"node\", \"address\": { \"$exists\": True } } },\n",
    "    { \"$project\": { \"_id\": False, \n",
    "                   \"city\": \"$address.city\", \n",
    "                   \"housenumber\": \"$address.housenumber\", \n",
    "                   \"postcode\": \"$address.postcode\", \n",
    "                   \"street\": \"$address.street\" } },\n",
    "    #{ \"$limit\": 10 }\n",
    "]\n",
    "addresses = pd.DataFrame(list(db.LaReunion.aggregate(pipeline)))\n",
    "addresses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addresses.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some missing data for all selected attributes (with one Nan for postcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 - City\n",
    "\n",
    "Let see if we can identify any problems with city attribute...  Can we recover the missing data for the city? \n",
    "\n",
    "> **note:** This will be possible if the postcode is not null... to crosscheck with the official postcal code database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from openstreetmap.data_gouv_fr import postalcode\n",
    "codes = postalcode.PostalCode(\"data/laposte_hexasmal.csv\").localityByPostcode()\n",
    "addresses.loc[:, \"city\"] = addresses.postcode.dropna().apply(lambda x: codes[int(x)].title())\n",
    "addresses[(addresses.city.isnull() == True) & (addresses.postcode.isnull() == False)].city.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addresses.city.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One remaining issue: a 'nan' value that could not be updated without extra information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addresses.set_index(\"postcode\")[\"city\"].dropna().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code addressed most remaining issues not handled during the initial cleansing step, for the City and PostCode fields, what about street? What are the remaining issues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To compare with the official database, some french characters have to be translated to their corresponding ASCII\n",
    "# what a pity for a french official database\n",
    "xtd = {ord(u'’'): u\"'\", ord(u'é'): u'e', ord(u'è'): u'e', ord(u'É'): u'E',}\n",
    "def tr(x):\n",
    "    return x.translate(xtd).upper()\n",
    "\n",
    "ways_referential = fantoir.FANTOIR().ways(\"data/FANTOIR1016\", \"974\")\n",
    "addresses[\"CHECKED\"] = addresses.street.dropna().apply(lambda x: tr(x) in ways_referential[\"FULL_NAME\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a step 2 mapping file for manual street name update ... updated file to be moved to update folder\n",
    "mapping = addresses[addresses.CHECKED == False][\"street\"].unique()\n",
    "df = pd.DataFrame.from_dict({ \"OLD\": mapping, \"NEW\": mapping })\n",
    "df.to_csv(\"audit/street_clean_step2.csv\",\n",
    "          encoding='utf-8', \n",
    "          index=False, \n",
    "          quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load updated file...and apply the mapping\n",
    "> **note**: not all street will be updated (limited to illustration purpose only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "updated_mapping = pd.read_csv(\"update/street_clean_step2.csv\", encoding='utf-8').set_index(\"NEW\")[\"OLD\"].to_dict()\n",
    "addresses.loc[:, \"street\"] = addresses.street.apply(lambda x: x if x not in updated_mapping.keys() \n",
    "                                                    else updated_mapping[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have identify some rules to (partially) update the addresses, why not updating the mongo database..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Postal Code and City **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n in db.LaReunion.find({ \"type\": \"node\", \n",
    "                            \"address\": { \"$exists\": True }, \n",
    "                            \"address.postcode\": { \"$exists\": True } }):\n",
    "    postcode = n[\"address\"][\"postcode\"].replace(' ', '')\n",
    "    db.LaReunion.update_one({ \"_id\": n[\"_id\"] }, { \"$set\": { \"address.postcode\":  postcode } }, upsert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in db.LaReunion.find({ \"type\": \"node\", \n",
    "                            \"address\": { \"$exists\": True }, \n",
    "                            \"address.postcode\": { \"$exists\": True } }):\n",
    "    city = codes[int(n[\"address\"][\"postcode\"])]\n",
    "    db.LaReunion.update_one({ \"_id\": n[\"_id\"] }, { \"$set\": { \"address.city\":  city } }, upsert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    { \"$match\": { \"type\": \"node\", \"address\": { \"$exists\": True }, \"address.postcode\": { \"$exists\": True } } },\n",
    "    { \"$project\": { \"_id\": False, \n",
    "                   \"city\": \"$address.city\", \n",
    "                   \"housenumber\": \"$address.housenumber\", \n",
    "                   \"postcode\": \"$address.postcode\", \n",
    "                   \"street\": \"$address.street\" } },\n",
    "    { \"$limit\": 10 }\n",
    "]\n",
    "pd.DataFrame(list(db.LaReunion.aggregate(pipeline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pretty(list(db.LaReunion.find({ \n",
    "        \"type\": \"node\", \n",
    "        \"address\": { \"$exists\": True }, \n",
    "        \"address.city\": { \"$exists\": False },\n",
    "        \"address.postcode\": { \"$exists\": False }}).limit(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still some cleaning to be done... but not possible with the information we have in hands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Conclusion\n",
    "\n",
    "The dataset is far from being complete and accurate. The different steps followed during the cleansing process has demonstrated that the dataset can be partially completed and made more accurate with some simple rules and correlation with some external databases (for French Area, the official database is publically available or referenced from http://data.gouv.fr). \n",
    "\n",
    "The cleansing process described above did not deliver a clean and fully accurate database as a lot a of specific rules need to be put in place. The number of different contributors probably influenced the way street name when populated into the database. This is clearly an area where an automated validation process (during changes/updates integration) could improve the quality: such automated process could rely (for French Area) on official ways referential available from http://data.gouv.fr (references of such database are listed in the source code generated for this project, which include information for postcode, city, street name). \n",
    "\n",
    "In addition to the referential databases, some standard regular expressions (such as Phone Number, Street Name, PostCode..) could be defined (and customized by country) and applied during changes/updates integration to reject or validate the user inputs.\n",
    "\n",
    "Another improvment that could lead to a better quality and standardization of the dataset is the used of standard ontology. Possible ways to move in that direction:\n",
    "-1 http://wiki.openstreetmap.org/wiki/OSMonto: the main advantage is that it stays very close to the existing tags from openstreetmap, but will not allow to easily connect to other source of information without additional development\n",
    "-2 align to a well defined RDF schema such as https://schema.org/Place or equivalent: the main advantage is the inter-operability of the different database allowing cross-validation of the data.\n",
    "\n",
    "For the second way, it means a big changes and migration effort will be significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
